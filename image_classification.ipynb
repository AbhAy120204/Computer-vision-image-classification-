{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: C:\\Users\\abhay\\Computer vision\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to the zip file\n",
    "zip_file = r\"C:\\Users\\abhay\\Computer vision\\comp5623m-artificial-intelligence.zip\"\n",
    "\n",
    "# Destination folder (same directory as the script)\n",
    "extract_to = r\"C:\\Users\\abhay\\Computer vision\"\n",
    "\n",
    "# Create the destination folder if it doesn't exist\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "print(f\"Files extracted to: {extract_to}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader,Dataset\n",
    "from torch.hub import load_state_dict_from_url\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for loading datasets\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    # Initialize the dataset with image directory and transform\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.class_names = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {class_name: i for i, class_name in enumerate(self.class_names)}\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for class_name in self.class_names:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.endswith('.JPEG'):\n",
    "                    self.images.append(os.path.join(class_dir, filename))\n",
    "                    self.labels.append(self.class_to_idx[class_name])\n",
    "\n",
    "    # This function returns the number of samples in the dataset.   \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    # This function returns the image and the label index.\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        image = torchvision.datasets.folder.default_loader(image_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloading(transform):\n",
    "    # Load the dataset of images and apply the transformation\n",
    "    dataset = CustomImageDataset(root_dir='/kaggle/input/train-dataset/train_set/train_set')\n",
    "    \n",
    "    valid_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Set the random seed for reproducibility\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    \n",
    "    # Splitting the dataset for validation and training in an 80:20 ratio     \n",
    "    training_size = int(0.8 * len(dataset))\n",
    "    validation_size = len(dataset) - training_size\n",
    "    training_dataset, validation_dataset = torch.utils.data.random_split(dataset, [training_size, validation_size])\n",
    "    \n",
    "    training_dataset.dataset.transform = transform\n",
    "    validation_dataset.dataset.transform = valid_transform\n",
    "\n",
    "    # Create a DataLoader for the training set and validation set\n",
    "    training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=16, num_workers=2, shuffle=True, generator=torch.Generator().manual_seed(0))\n",
    "    validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=16, num_workers=2, shuffle=False)\n",
    "\n",
    "    # Get the class names (labels) corresponding to the subfolders in the dataset\n",
    "    class_names = dataset.class_names\n",
    "    \n",
    "    # Return the datasets and dataloaders for training and validation, along with the class names\n",
    "    return training_dataset, validation_dataset, training_dataloader, validation_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/kaggle/input/train-dataset/train_set/train_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m train_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      4\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize([\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m], [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m])\n\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the training and validation datasets, and create dataloaders for them\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m training_dataset, validation_dataset, training_dataloader, validation_dataloader, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataloading\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_transform\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36mdataloading\u001b[1;34m(transform)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdataloading\u001b[39m(transform):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Load the dataset of images and apply the transformation\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCustomImageDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/train-dataset/train_set/train_set\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     valid_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      6\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      7\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mNormalize([\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m], [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m])\n\u001b[0;32m      8\u001b[0m     ])\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Set the random seed for reproducibility\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m, in \u001b[0;36mCustomImageDataset.__init__\u001b[1;34m(self, root_dir, transform)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir \u001b[38;5;241m=\u001b[39m root_dir\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_to_idx \u001b[38;5;241m=\u001b[39m {class_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, class_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names)}\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/kaggle/input/train-dataset/train_set/train_set'"
     ]
    }
   ],
   "source": [
    "# Define the image preprocessing steps\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load the training and validation datasets, and create dataloaders for them\n",
    "training_dataset, validation_dataset, training_dataloader, validation_dataloader, class_names = dataloading(train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
